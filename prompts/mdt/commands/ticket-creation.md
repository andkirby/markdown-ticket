# ADR Creation Workflow for MCP mdt-all (v6)

Interactive workflow for AI agents creating architectural decision records (ADRs) using MCP mdt-all ticket system with structured questioning.

**Two Modes Available**:
- **Requirements Mode**: Describe WHAT outcome is needed, defer HOW to `/mdt:architecture`
- **Full Specification Mode**: Describe both WHAT and HOW with concrete artifacts

**Core Principle**: In Full Specification mode, specify concrete artifacts (files, components, endpoints, methods). In Requirements mode, specify outcomes and constraints without implementation details.

## User Input

```text
$ARGUMENTS
```

## Session Context

Use `{TICKETS_PATH}` in all file path templates below (if it's not defined read ticketsPath key from .mdt-config.toml).

You **MUST** consider the user input before proceeding (if not empty). User may provide:
- Initial description of the change needed
- Specific files/components involved
- Problem statement or user story
- Technical requirements or constraints

Parse this input for context before starting the questioning workflow.

## Critical Rules

### Both Modes
1. **NO YAML frontmatter** - Auto-generated by MCP
2. **NO prose paragraphs** - Use bullets, tables, or lists only
3. **NO placeholders** - Replace ALL with concrete details
4. **NO fabricated metrics** - Only if: (a) baseline exists, (b) verifiable, (c) explicitly required
5. **NO unmeasurable claims** - No adoption rates, productivity, satisfaction, time estimates
6. **NO generic adjectives** - No "user-friendly", "robust", "scalable" without specifics
7. **Tables for comparisons** - Use tables for alternatives and specifications
8. **Keep concise** - Target 150-300 lines
9. **Proper headers** - Use `##` for main sections, `###` for subsections, NO bold text as headers

### Full Specification Mode Only
10. **NO behavioral descriptions** - Say "Component Y" not "Component that does Y"
11. **NO implementation code** - No code snippets, API signatures, config files in sections 1-6
12. **ARTIFACT REFERENCES REQUIRED** - Every technical point must name a file/component/endpoint

### Requirements Mode Only
13. **OUTCOME-FOCUSED** - Describe what should happen, not how to implement it
14. **NO SPECIFIC FILES** - Use area descriptions (e.g., "Frontend authentication") not file paths
15. **NO IMPLEMENTATION APPROACH** - Defer decisions to `/mdt:architecture` workflow

## Formatting Rules (CRITICAL)

- **Main sections**: `## 1. Description`, `## 2. Decision`, etc. (Use exact section names)
- **Subsections**: `### Problem`, `### Affected Artifacts`, etc.
- **NO bold text as section headers** - NEVER use `**Header**` as a section header
- **ALWAYS use markdown headers**: `###` for subsections, `####` for deeper subsections
- **Lists stay as lists** - Do NOT wrap bullet lists in code blocks
- **Code blocks ONLY in Section 7** (Deployment) for actual deployment commands
- **One H1 only** - The document title at the top, nothing else
- **NO duplicate headers** - Each section header must be unique, never repeat `## 1. Description` twice

## Workflow Execution

### Step 1: Analyze Context

1. Parse user input from `$ARGUMENTS` for:
   - Stated problem or need
   - Mentioned files/components/endpoints
   - Technical constraints or requirements
   - Desired outcome

2. Scan conversation history for:
   - Recent code discussions
   - File paths mentioned
   - Error messages or bugs discussed
   - Performance concerns raised

3. If project context available, identify:
   - Codebase structure (frontend/backend/shared)
   - Existing patterns and conventions
   - Related CRs or tickets

### Step 2: Interactive Question Flow

Ask questions using `AskUserQuestion` tool to gather specification information. **Maximum 10 questions total**. Skip questions if information is already clear from context.

#### Question 0: Specification Depth (Required - Ask First)

```
Question: How detailed should this ticket be?
Header: Depth
Options:
- Requirements only: Describe WHAT outcome is needed, defer HOW to architecture workflow (Recommended for complex/uncertain features)
- Full specification: Describe both WHAT and HOW with concrete artifacts (Recommended for small/well-understood changes)
```

**Use answer to**:
- Determine which document structure to use
- Control which questions to ask (skip 4, 5, 7 in Requirements mode)
- Set expectation for downstream workflows

**Store as**: `SPEC_MODE` = "requirements" | "full"

---

#### Question 1: Change Type (Required)

```
Question: What type of change are you making?
Header: CR Type
Options:
- Feature Enhancement: Add new functionality or capability
- Bug Fix: Fix existing defect or broken behavior
- Architecture: System design or structural change
- Technical Debt: Code quality improvement or refactoring
- Documentation: Project documentation updates
- Research: Hypothesis-driven validation or investigation work
```

**Use answer to**:
- Set MCP `type` parameter
- Determine verification approach (Section 6)
- Frame remaining questions
- Set default for Requirements Scope (Question 1b)

**Store as**: `CR_TYPE`

#### Question 1b: Requirements Scope (Required)

Ask after Question 1, with smart defaults based on CR type:

```
Question: What level of requirements documentation is needed?
Header: Req Scope
Options (show default first based on CR_TYPE):
```

**Defaults by CR_TYPE**:
| CR Type | Default Option | Other Options |
|---------|----------------|---------------|
| Feature Enhancement | `full`: Generate EARS + FR + NFR specs | `brief`, `none` |
| Bug Fix | `brief`: Bug description + fix criteria | `full`, `none` |
| Architecture | `none`: Skip requirements, use /mdt:architecture | `full`, `brief` |
| Technical Debt | `none`: Skip requirements, use /mdt:architecture | `full`, `brief` |
| Documentation | `none`: No requirements needed | `brief` |

**Option descriptions**:
- `full`: Full EARS behavioral specs + FR + NFR tables (Recommended for new capabilities)
- `brief`: Minimal requirements, fix criteria only (Recommended for bug fixes)
- `preservation`: Behavior lock tests for refactoring (Recommended when preserving behavior)
- `none`: Skip requirements workflow (Recommended for structural changes)

**Override prompt** (show when CR type suggests `none` but user may need requirements):
```
Default for {CR_TYPE} is "none" (skip requirements).

Does this CR introduce NEW behaviors or capabilities?
- No, purely structural → keep: none
- Yes, adds new capabilities → change to: full
- Yes, modifies existing behavior → change to: brief
```

**Use answer to**:
- Set `REQUIREMENTS_SCOPE` value
- Include in generated CR content
- Guide post-creation workflow suggestions

**Store as**: `REQUIREMENTS_SCOPE` = "full" | "brief" | "preservation" | "none"

#### Question 2: Trigger/Motivation (Required)

```
Question: What triggered this change?
Header: Motivation
Options:
- User requirement: Specific user/stakeholder need (Recommended for Feature Enhancement)
- Technical limitation: Current system can't meet requirement
- Bug/defect: Something is broken or behaving incorrectly
- Performance issue: System is too slow or resource-intensive
- Maintenance burden: Code is hard to understand or maintain
- Architectural gap: Missing architectural component or pattern
```

**Use answer to**:
- Frame Problem section (1.1)
- Identify affected artifacts
- Guide rationale development

#### Question 3: Artifact Areas (Conditional Multi-select)

Only ask if not clear from context.

```
Question: Which areas of the codebase are involved?
Header: Areas
MultiSelect: true
Options:
- Frontend components: UI components in src/components/
- Backend services: Business logic in server/services/
- API endpoints: REST/GraphQL endpoints
- Database: Schema, queries, or migrations
- Configuration: Config files or environment variables
- Shared code: Utilities in shared/ directory
- Tests: Test files or test infrastructure
```

**Use answer to**:
- Populate Affected Artifacts section (1.2)
- Guide specific file/component questions
- Set scope boundaries

#### Question 4: Specific Files Modified (Full Specification Mode Only)

**SKIP if `SPEC_MODE` = "requirements"** - Defer to `/mdt:architecture`

Only ask if specific files not mentioned in context.

```
Question: Which existing files need to be modified?
Format: Provide comma-separated file paths (≤5 files)
Example: src/services/UserService.ts, server/routes/users.ts
Constraint: ≤50 characters total
```

**Use answer to**:
- Populate Modified Artifacts table (Section 4.2)
- Identify integration points
- Clarify scope

#### Question 5: New Artifacts (Full Specification Mode Only)

**SKIP if `SPEC_MODE` = "requirements"** - Defer to `/mdt:architecture`

Only ask if new files/components not mentioned.

```
Question: What new files or components will be created?
Format: Provide comma-separated paths (≤5 items)
Example: src/services/AuthService.ts, /api/auth/token
Constraint: ≤50 characters total
```

**Use answer to**:
- Populate New Artifacts table (Section 4.1)
- Define scope boundaries
- Set integration points

#### Question 6: Decision Status (Mode-dependent)

**Full Specification Mode:**
```
Question: Have you decided on an implementation approach?
Header: Decision Status
Options:
- Decided with alternatives: I know the approach and considered alternatives (Recommended - produces complete CR)
- Decided, no alternatives: I know the approach but didn't evaluate alternatives
- Need alternatives: Help me evaluate different approaches
- Exploratory: Not sure yet, need to explore options
```

**Requirements Mode:**
```
Question: What's the decision status for this requirement?
Header: Decision Status
Options:
- Constraints known: I know the constraints, architecture can decide approach (Recommended)
- Exploratory: Need to explore what's possible first
- Urgent: Need quick solution, will refine later
```

**Use answer to**:
- Determine if Alternatives table can be populated (Section 3)
- Set CR status (Proposed vs. Exploratory)
- Guide approach documentation depth

#### Question 7: Chosen Approach (Full Specification Mode Only)

**SKIP if `SPEC_MODE` = "requirements"** - Implementation approach determined by `/mdt:architecture`

Only ask if Question 6 answered "Decided..." option.

```
Question: Describe your chosen approach in one sentence
Format: ≤15 words
Example: Add JWT middleware to Express server for token-based authentication
```

**Use answer to**:
- Populate Chosen Approach section (2.1)
- Frame rationale bullets
- Set alternatives table context

#### Question 8: Alternatives/Exploration (Mode-dependent)

**Full Specification Mode** - Only ask if Question 6 answered "Decided with alternatives":
```
Question: What alternative approaches did you consider?
Header: Alternatives
MultiSelect: true
Options:
- Different library/framework: Considered alternative tech choice
- Different architecture pattern: Considered different design pattern
- Different implementation approach: Same tech, different approach
- No-code solution: Configuration or existing tool instead
- Defer/don't fix: Considered not doing this change
- Other: Specify in ≤10 words
```

**Requirements Mode** - Only ask if Question 6 answered "Exploratory":
```
Question: What approaches should architecture explore?
Header: Exploration
MultiSelect: true
Options:
- Multiple libraries: Evaluate different tech options
- Build vs. buy: Compare custom vs. existing solutions
- Performance trade-offs: Evaluate speed vs. complexity
- Integration options: Compare integration approaches
- Leave open: Let architecture decide without constraints
```

**Use answer to**:
- Full Mode: Populate Alternatives Considered table (Section 3)
- Requirements Mode: Populate Open Questions table (Section 3)
- Identify constraints and preferences

#### Question 9: Success Criteria (Conditional Multi-select)

Only ask if not clear from context.

```
Question: How will you verify this change is complete?
Header: Verification
MultiSelect: true
Options:
- Files exist: Specific files created with expected exports/methods
- Tests pass: Unit, integration, or e2e tests pass
- Endpoints work: API endpoints return expected responses
- Performance met: Measured performance meets target
- Manual verification: Specific manual test steps work
- Documentation updated: Docs reflect the changes
```

**Use answer to**:
- Populate Acceptance Criteria (Section 5)
- Define verification approach (Section 6)
- Set completion criteria

#### Question 10: Performance Targets (Conditional)

Only ask if "Performance met" selected in Question 9 OR Question 2 answered "Performance issue".

```
Question: Do you have measurable performance targets?
Header: Performance
Options:
- Yes, with baseline: I have current baseline and target metrics (Recommended)
- Yes, target only: I have target but need to measure baseline
- No metrics yet: Need to establish baseline and target
- Not applicable: Change not performance-related
```

**Use answer to**:
- Populate Metrics section (6.2) if baseline exists
- Add acceptance criteria for performance
- Flag if baseline measurement needed

### Step 3: Generate CR Content

Using answers from questioning flow and context from Step 1:

1. **Generate Title**: Concise description (≤10 words)
   - Pattern: `[Type] Brief description of change`
   - Example: `Add JWT authentication middleware to API`

2. **Select Document Structure** based on `SPEC_MODE`:
   - **Full Specification Mode**: Use "Full Specification Mode Structure" (7 sections)
   - **Requirements Mode**: Use "Requirements Mode Structure" (5 sections)

3. **Populate Sections** according to selected structure:

   **Full Specification Mode**:
   - Use artifact-specific language from answers
   - Transform behavioral descriptions to artifact references
   - Fill tables with concrete specifications
   - Add acceptance criteria as checkboxes

   **Requirements Mode**:
   - Focus on outcomes and constraints
   - Avoid specific file paths or implementation details
   - Use area descriptions instead of artifact references
   - Frame acceptance criteria as user/system outcomes

4. **Mark Unknown Sections**: If information missing after all questions:
   - Add note: `(Requires clarification - run mdt-clarification.md workflow)`
   - Do NOT use placeholders or TODOs
   - Do NOT fabricate information

5. **Validate Content** against Quality Checklist (mode-specific) before submission

### Step 4: Create CR via MCP

```json
{
  "project": "PROJECT_CODE",
  "type": "Architecture|Feature Enhancement|Bug Fix|Technical Debt|Documentation",
  "data": {
    "title": "Generated title from Step 3",
    "phaseEpic": "Optional part/epic if mentioned in context",
    "assignee": "Optional assignee if mentioned in context",
    "content": "Full markdown content (no YAML frontmatter)"
  }
}
```

**Project Code Discovery**: If not in context, use:
```bash
cat .mdt-config.toml | grep 'code = '
```

### Step 5: Post-Creation Actions

After successful CR creation:

1. **Report CR Key**: Inform user of created CR (e.g., "Created MDT-078")

2. **Suggest Next Steps** based on `REQUIREMENTS_SCOPE`:

   **REQUIREMENTS_SCOPE = "full"**:
   ```
   /mdt:requirements → Full EARS + FR + NFR specifications
           ↓
   /mdt:bdd → E2E acceptance tests (user-visible behavior)
           ↓
   /mdt:assess → evaluate affected code fitness (optional)
           ↓
   /mdt:architecture → determines HOW (artifacts, patterns, parts)
           ↓
   /mdt:tests → module-level tests from architecture
           ↓
   /mdt:tasks → task breakdown
           ↓
   /mdt:implement → execution (all tests go GREEN)
   ```

   **REQUIREMENTS_SCOPE = "brief"**:
   ```
   /mdt:requirements → Brief requirements (bug description + fix criteria)
           ↓
   /mdt:bdd → E2E test reproducing the bug (RED)
           ↓
   /mdt:architecture → design fix approach
           ↓
   /mdt:tests → module tests for fix
           ↓
   /mdt:tasks → task breakdown
           ↓
   /mdt:implement → execution (bug test goes GREEN)
   ```

   **REQUIREMENTS_SCOPE = "preservation"**:
   ```
   /mdt:assess → identify behavior to preserve
           ↓
   /mdt:bdd --prep → lock E2E user journeys (GREEN)
           ↓
   /mdt:architecture → design target structure
           ↓
   /mdt:tests --prep → lock module behavior (GREEN)
           ↓
   /mdt:tasks → task breakdown
           ↓
   /mdt:implement → execution (all tests stay GREEN)
   ```

   **REQUIREMENTS_SCOPE = "none"**:
   ```
   /mdt:assess → evaluate affected code (optional)
           ↓
   /mdt:architecture → design directly
           ↓
   /mdt:tasks → task breakdown
           ↓
   /mdt:implement → execution
   ```

   **All Scopes**:
   - If sections marked "Requires clarification": Suggest running `/mdt:clarification`
   - If exploratory CR: Suggest implementation spike before approval
   - If ready: Suggest marking as "Approved" for implementation

3. **Offer Immediate Refinement**: Ask if user wants to:
   - Add more detail to any section
   - Run clarification workflow now
   - Make any corrections

---

## Document Structure

Choose structure based on `SPEC_MODE` from Question 0.

---

### Full Specification Mode Structure

Use this structure when `SPEC_MODE` = "full"

## 1. Description

### Requirements Scope
`{REQUIREMENTS_SCOPE}` — `full` | `brief` | `preservation` | `none`

### Problem
Write 2-3 bullets describing specific technical issues:
- Specific technical issue with artifact reference
- Missing capability with artifact reference
- Architectural gap with artifact reference

### Affected Artifacts
List files, components, and endpoints affected:
- `path/to/file.ts` (specific concern)
- `Component/ModuleName` (specific concern)
- `/api/endpoint` (specific concern)

### Scope
Clearly define boundaries:
- **Changes**: What will be modified/created
- **Unchanged**: What stays the same

## 2. Decision

### Chosen Approach
One sentence describing the decision.

### Rationale
Write 3-5 bullets with specific, measurable reasons:
- Technical reason (specific, measurable)
- Technical reason (specific, measurable)
- Trade-off accepted (specific)

## 3. Alternatives Considered

Use table format only:

| Approach | Key Difference | Why Rejected |
|----------|---------------|--------------|
| **Chosen Approach** | One-line description | **ACCEPTED** - Reason for choosing |
| Option A | One-line description | Specific reason |
| Option B | One-line description | Specific reason |

**IMPORTANT**: Mark the chosen approach with **ACCEPTED** in the "Why Rejected" column

## 4. Artifact Specifications

### New Artifacts

| Artifact | Type | Purpose |
|----------|------|---------|
| `src/components/X.tsx` | Component | Feature X UI |
| `/api/new-endpoint` | Endpoint | Data access |
| `services/Y.ts` | Service | Business logic |

### Modified Artifacts

| Artifact | Change Type | Modification |
|----------|-------------|--------------|
| `path/to/file.ts` | Method added | `methodName()` |
| `Component` | Prop changed | Added `propName` |

### Integration Points

| From | To | Interface |
|------|----|-----------|
| Component X | Service Y | Method Z |
| API endpoint | Database | Query type |

### Key Patterns
List patterns as bullets:
- Pattern name: Where applied (artifact reference)
- Pattern name: Where applied (artifact reference)

## 5. Acceptance Criteria

### Functional
Write artifact-specific, testable criteria as checkboxes (NOT in code blocks):
- [ ] File X exports method Y
- [ ] Component Z renders when condition A
- [ ] Endpoint /api/path returns status 200 for input B

### Non-Functional
Write measurable criteria as checkboxes (NOT in code blocks):
- [ ] Test coverage > X% (current: Y%)
- [ ] Operation completes in < Nms (current: Mms)
- [ ] Error type E thrown when condition F

### Testing
Write specific test cases as bullets (NOT in code blocks):
- Unit: Test file X, function Y, input Z → output W
- Integration: Component A + Service B → State C
- Manual: Action sequence → verify result

## 6. Verification

### By CR Type
Choose the appropriate verification approach:
- **Bug Fix**: Issue X no longer occurs in test case Y
- **Feature**: Artifact X exists and test Y passes
- **Refactoring**: Tests pass, metric M improved (before: A, after: B)
- **Performance**: Operation X < target (baseline: Y, target: Z)
- **Documentation**: Files [list] contain sections [list]

### Metrics
ONLY include metrics if ALL three conditions met:
1. Baseline measurement exists
2. Can be verified through testing/measurement
3. CR explicitly targets this metric

If no metrics applicable, list verifiable artifacts that exist after implementation.

## 7. Deployment

### Simple Changes
Use bullets:
- Deployment method
- Configuration changes required

### Complex Changes
Use table format:

| Part | Artifacts Deployed | Rollback |
|-------|-------------------|----------|
| 1 | File A, B | Revert commits X, Y |
| 2 | File C, D | Disable feature flag |

Code blocks ARE allowed in this section for deployment commands:
```bash
npm run deploy
kubectl apply -f config.yaml
```

---

### Requirements Mode Structure

Use this structure when `SPEC_MODE` = "requirements"

## 1. Description

### Requirements Scope
`{REQUIREMENTS_SCOPE}` — `full` | `brief` | `preservation` | `none`

### Problem
Write 2-3 bullets describing the problem in outcome terms:
- What users/system cannot do currently
- What pain point or limitation exists
- What opportunity is being missed

### Affected Areas
List general areas (NOT specific files):
- Frontend: Which user-facing area
- Backend: Which service domain
- Database: What data concerns
- Integration: What external systems

### Scope
Clearly define boundaries:
- **In scope**: What outcomes this CR addresses
- **Out of scope**: What outcomes are NOT addressed

## 2. Desired Outcome

### Success Conditions
Write outcome statements (NOT implementation):
- When X happens, Y should result
- Users should be able to Z
- System should support W

### Constraints
List known constraints that architecture must respect:
- Must integrate with existing system X
- Cannot require external service Y
- Must maintain backward compatibility with Z
- Performance must not degrade below N

### Non-Goals
Explicitly state what this CR does NOT aim to achieve:
- Not changing existing behavior X
- Not optimizing for use case Y

## 3. Open Questions

Questions to resolve during architecture/design:

| Area | Question | Constraints |
|------|----------|-------------|
| Technology | Which library/framework to use? | List any technology constraints |
| Architecture | What pattern best fits? | List any architectural constraints |
| Integration | How to connect with existing systems? | List any integration constraints |
| Performance | What trade-offs are acceptable? | List any performance requirements |

### Known Constraints
List constraints that architecture must respect:
- Must use existing system/technology X
- Must not require new infrastructure Y
- Must maintain compatibility with Z

### Decisions Deferred
Explicitly list what this CR does NOT decide:
- Implementation approach (determined by `/mdt:architecture`)
- Specific artifacts (determined by `/mdt:architecture`)
- Task breakdown (determined by `/mdt:tasks`)

## 4. Acceptance Criteria

### Functional (Outcome-focused)
Write testable outcomes as checkboxes (NOT artifact-specific):
- [ ] User can perform action X
- [ ] System responds with Y when Z occurs
- [ ] Data persists correctly after operation W

### Non-Functional
Write measurable criteria as checkboxes:
- [ ] Response time < Nms for operation X
- [ ] System handles N concurrent users
- [ ] Error rate < X% under normal load

### Edge Cases
List edge cases that must be handled:
- What happens when input is invalid
- What happens when dependent service unavailable
- What happens when user cancels mid-operation

## 5. Verification

### How to Verify Success
Describe verification approach (architecture will detail tests):
- Manual verification: What user actions prove success
- Automated verification: What behaviors to test
- Performance verification: What to measure

---

### Research Mode Structure

Use this structure when `SPEC_MODE` = "requirements" and `CR_TYPE` = "Research"

## 1. Description

### Requirements Scope
`{REQUIREMENTS_SCOPE}` — `full` | `brief` | `preservation` | `none`

### Research Objective
Clear statement of what hypothesis or question this research validates:
- Primary hypothesis or research question
- What decision depends on this research
- What uncertainty this research resolves

### Research Context
Write 2-3 bullets providing context:
- What problem or gap motivates this research
- What constraints or assumptions exist
- What prior work or knowledge is relevant

### Scope
Clearly define research boundaries:
- **In scope**: What questions this research addresses
- **Out of scope**: What questions are NOT addressed

## 2. Research Questions

Use table format for all research questions:

| ID | Research Question | Success Criteria | Priority |
|----|-------------------|------------------|----------|
| RQ1 | Specific question to answer | Measurable outcome | High/Medium/Low |
| RQ2 | Specific question to answer | Measurable outcome | High/Medium/Low |
| RQ3 | Specific question to answer | Measurable outcome | High/Medium/Low |

**Guidelines**:
- Each RQ must be answerable with evidence
- Success criteria must be observable/measurable
- Priority guides resource allocation if time-constrained

## 3. Validation Approach

### Research Method
Describe how each RQ will be validated:
- RQ1: Method (e.g., literature review, prototype, experiment, analysis)
- RQ2: Method with specific data sources or tools
- RQ3: Method with measurement approach

### Data Sources
List sources of evidence for each RQ:
- RQ1: Specific documents, codebases, systems to analyze
- RQ2: Specific user groups, metrics, or benchmarks
- RQ3: Specific technologies, frameworks, or patterns to evaluate

### Success Metrics
Define measurable outcomes:
- Evidence threshold for answering each RQ
- Confidence level required for conclusions
- Decision criteria for proceeding vs. pivoting

## 4. Acceptance Criteria

### Research Completion
Checkboxes for each RQ (NOT in code blocks):
- [ ] RQ1 answered with evidence: [summary of findings]
- [ ] RQ2 answered with evidence: [summary of findings]
- [ ] RQ3 answered with evidence: [summary of findings]

### Decision Outcomes
Define possible outcomes and next steps:
- If hypothesis confirmed: [specific action or CR to create]
- If hypothesis refuted: [alternative approach or pivot]
- If inconclusive: [what additional work needed]

### Artifacts Produced
List deliverables from this research:
- Research summary document with findings
- Evidence data (benchmarks, prototypes, analysis)
- Recommendation: [Create new CR / Modify existing CR / Abandon approach]

## 5. Dependencies & Next Steps

### Prerequisites
What must exist before research starts:
- Access to systems, data, or documentation
- Setup or configuration required
- Stakeholder input or approval needed

### Blocked By
List any dependencies:
- [ ] CR-XXX: Prior research or implementation
- [ ] System Y: Access to environment or tool
- [ ] Stakeholder Z: Input or approval

### Next Steps After Research
Based on research outcomes:
- **Positive outcome**: Create CR for [specific feature/change]
- **Negative outcome**: Pivot to [alternative approach]
- **Inconclusive**: Additional research needed for [specific RQ]

---

## Quality Checklist

### Both Modes
- [ ] NO prose paragraphs - use bullets, tables, or lists only
- [ ] NO generic adjectives without supporting specifics
- [ ] NO fabricated metrics - only include if baseline exists
- [ ] Section headers use `##` and `###`, NEVER bold text like `**Header**`
- [ ] NO duplicate headers (never repeat the same section header)
- [ ] Lists are NOT wrapped in code blocks
- [ ] Only ONE H1 (`#`) header - the document title

### Full Specification Mode Only
- [ ] Every technical statement references a concrete artifact (file/component/endpoint/method)
- [ ] Problem section references specific artifacts that have the problem
- [ ] Alternatives table shows concrete differences, not philosophy
- [ ] Section 4 uses tables for artifact specifications
- [ ] Acceptance criteria reference specific artifacts and tests
- [ ] Verification is measurable or references concrete artifacts
- [ ] All metrics have baselines OR section describes artifacts only
- [ ] Alternatives table clearly marks chosen approach with **ACCEPTED**

### Requirements Mode Only
- [ ] Problem section describes outcomes/limitations, NOT specific files
- [ ] NO specific file paths or implementation details
- [ ] Acceptance criteria are outcome-focused (user/system behaviors)
- [ ] Section 3 "Open Questions" lists decisions for architecture to make
- [ ] "Known Constraints" lists boundaries architecture must respect
- [ ] "Decisions Deferred" explicitly states what this CR does NOT decide

### Research Mode Only
- [ ] Research Objective clearly states hypothesis or question to validate
- [ ] Section 2 Research Questions table includes ID, question, success criteria, priority
- [ ] Each RQ has measurable success criteria (observable outcomes)
- [ ] Validation Approach specifies concrete methods and data sources
- [ ] Acceptance Criteria include decision outcomes for each possible result
- [ ] Dependencies & Next Steps list prerequisites and post-research actions

## Common Errors to Avoid

### Formatting Errors (Both Modes)

❌ **WRONG**: `**Problem**` (bold as header)
✅ **CORRECT**: `### Problem` (markdown header)

❌ **WRONG**: Duplicate headers like `## 1. Description` appearing twice
✅ **CORRECT**: Each header appears only once

### Full Specification Mode Errors

❌ **WRONG**: Behavioral descriptions like "Component that handles authentication"
✅ **CORRECT**: Artifact specifications like "`AuthService.ts` - Authentication logic"

### Requirements Mode Errors

❌ **WRONG**: "Modify `src/services/AuthService.ts` to add validation"
✅ **CORRECT**: "Authentication must validate user credentials before granting access"

❌ **WRONG**: "Add JWT middleware to Express server"
✅ **CORRECT**: "Users must be able to maintain session across requests"

### Research Mode Errors

❌ **WRONG**: Research Questions without success criteria or priority
✅ **CORRECT**: Table with ID, question, measurable criteria, priority level

❌ **WRONG**: Vague validation approach like "investigate options"
✅ **CORRECT**: Specific method (e.g., "prototype and benchmark X vs Y")

❌ **WRONG**: Missing decision outcomes for different research results
✅ **CORRECT**: Clear actions for positive/negative/inconclusive outcomes

---

This ensures properly formatted specification documents - artifact-focused (Full Specification), outcome-focused (Requirements), or hypothesis-driven (Research).