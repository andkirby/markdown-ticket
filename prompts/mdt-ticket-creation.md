# ADR Creation Workflow for MCP mdt-all (v4 - Interactive Specification)

Interactive workflow for AI agents creating architectural decision records (ADRs) using MCP mdt-all ticket system with structured questioning.

**Core Principle**: Specify concrete artifacts (files, components, endpoints, methods), not behavioral descriptions. Every technical statement must reference what exists, not what it does.

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty). User may provide:
- Initial description of the change needed
- Specific files/components involved
- Problem statement or user story
- Technical requirements or constraints

Parse this input for context before starting the questioning workflow.

## Critical Rules

1. **NO YAML frontmatter** - Auto-generated by MCP
2. **NO prose paragraphs** - Use bullets, tables, or lists only
3. **NO behavioral descriptions** - Say "Component Y" not "Component that does Y"
4. **NO placeholders** - Replace ALL with concrete details
5. **NO fabricated metrics** - Only if: (a) baseline exists, (b) verifiable, (c) explicitly required
6. **NO unmeasurable claims** - No adoption rates, productivity, satisfaction, time estimates
7. **NO generic adjectives** - No "user-friendly", "robust", "scalable" without specifics
8. **NO implementation code** - No code snippets, API signatures, config files in sections 1-6
9. **ARTIFACT REFERENCES REQUIRED** - Every technical point must name a file/component/endpoint
10. **Tables for comparisons** - Use tables for alternatives and specifications
11. **Keep concise** - Target 150-300 lines
12. **Proper headers** - Use `##` for main sections, `###` for subsections, NO bold text as headers

## Formatting Rules (CRITICAL)

- **Main sections**: `## 1. Description`, `## 2. Decision`, etc. (Use exact section names)
- **Subsections**: `### Problem`, `### Affected Artifacts`, etc.
- **NO bold text as section headers** - NEVER use `**Header**` as a section header
- **ALWAYS use markdown headers**: `###` for subsections, `####` for deeper subsections
- **Lists stay as lists** - Do NOT wrap bullet lists in code blocks
- **Code blocks ONLY in Section 7** (Deployment) for actual deployment commands
- **One H1 only** - The document title at the top, nothing else
- **NO duplicate headers** - Each section header must be unique, never repeat `## 1. Description` twice

## Workflow Execution

### Step 1: Analyze Context

1. Parse user input from `$ARGUMENTS` for:
   - Stated problem or need
   - Mentioned files/components/endpoints
   - Technical constraints or requirements
   - Desired outcome

2. Scan conversation history for:
   - Recent code discussions
   - File paths mentioned
   - Error messages or bugs discussed
   - Performance concerns raised

3. If project context available, identify:
   - Codebase structure (frontend/backend/shared)
   - Existing patterns and conventions
   - Related CRs or tickets

### Step 2: Interactive Question Flow

Ask questions using `AskUserQuestion` tool to gather artifact-specific information. **Maximum 10 questions total**. Skip questions if information is already clear from context.

#### Question 1: Change Type (Required)

```
Question: What type of change are you making?
Header: CR Type
Options:
- Feature Enhancement: Add new functionality or capability
- Bug Fix: Fix existing defect or broken behavior
- Architecture: System design or structural change
- Technical Debt: Code quality improvement or refactoring
- Documentation: Project documentation updates
```

**Use answer to**:
- Set MCP `type` parameter
- Determine verification approach (Section 6)
- Frame remaining questions

#### Question 2: Trigger/Motivation (Required)

```
Question: What triggered this change?
Header: Motivation
Options:
- User requirement: Specific user/stakeholder need (Recommended for Feature Enhancement)
- Technical limitation: Current system can't meet requirement
- Bug/defect: Something is broken or behaving incorrectly
- Performance issue: System is too slow or resource-intensive
- Maintenance burden: Code is hard to understand or maintain
- Architectural gap: Missing architectural component or pattern
```

**Use answer to**:
- Frame Problem section (1.1)
- Identify affected artifacts
- Guide rationale development

#### Question 3: Artifact Areas (Conditional Multi-select)

Only ask if not clear from context.

```
Question: Which areas of the codebase are involved?
Header: Areas
MultiSelect: true
Options:
- Frontend components: UI components in src/components/
- Backend services: Business logic in server/services/
- API endpoints: REST/GraphQL endpoints
- Database: Schema, queries, or migrations
- Configuration: Config files or environment variables
- Shared code: Utilities in shared/ directory
- Tests: Test files or test infrastructure
```

**Use answer to**:
- Populate Affected Artifacts section (1.2)
- Guide specific file/component questions
- Set scope boundaries

#### Question 4: Specific Files Modified (Conditional Short-answer)

Only ask if specific files not mentioned in context.

```
Question: Which existing files need to be modified?
Format: Provide comma-separated file paths (≤5 files)
Example: src/services/UserService.ts, server/routes/users.ts
Constraint: ≤50 characters total
```

**Use answer to**:
- Populate Modified Artifacts table (Section 4.2)
- Identify integration points
- Clarify scope

#### Question 5: New Artifacts (Conditional Short-answer)

Only ask if new files/components not mentioned.

```
Question: What new files or components will be created?
Format: Provide comma-separated paths (≤5 items)
Example: src/services/AuthService.ts, /api/auth/token
Constraint: ≤50 characters total
```

**Use answer to**:
- Populate New Artifacts table (Section 4.1)
- Define scope boundaries
- Set integration points

#### Question 6: Decision Status (Required)

```
Question: Have you decided on an implementation approach?
Header: Decision Status
Options:
- Decided with alternatives: I know the approach and considered alternatives (Recommended - produces complete CR)
- Decided, no alternatives: I know the approach but didn't evaluate alternatives
- Need alternatives: Help me evaluate different approaches
- Exploratory: Not sure yet, need to explore options
```

**Use answer to**:
- Determine if Alternatives table can be populated (Section 3)
- Set CR status (Proposed vs. Exploratory)
- Guide approach documentation depth

#### Question 7: Chosen Approach (Conditional Short-answer)

Only ask if Question 6 answered "Decided..." option.

```
Question: Describe your chosen approach in one sentence
Format: ≤15 words
Example: Add JWT middleware to Express server for token-based authentication
```

**Use answer to**:
- Populate Chosen Approach section (2.1)
- Frame rationale bullets
- Set alternatives table context

#### Question 8: Alternatives Considered (Conditional Multi-select or Short-answer)

Only ask if Question 6 answered "Decided with alternatives".

```
Question: What alternative approaches did you consider?
Header: Alternatives
MultiSelect: true
Options:
- Different library/framework: Considered alternative tech choice
- Different architecture pattern: Considered different design pattern
- Different implementation approach: Same tech, different approach
- No-code solution: Configuration or existing tool instead
- Defer/don't fix: Considered not doing this change
- Other: Specify in ≤10 words
```

**Use answer to**:
- Populate Alternatives Considered table (Section 3)
- Identify rejection reasons
- Demonstrate decision-making process

#### Question 9: Success Criteria (Conditional Multi-select)

Only ask if not clear from context.

```
Question: How will you verify this change is complete?
Header: Verification
MultiSelect: true
Options:
- Files exist: Specific files created with expected exports/methods
- Tests pass: Unit, integration, or e2e tests pass
- Endpoints work: API endpoints return expected responses
- Performance met: Measured performance meets target
- Manual verification: Specific manual test steps work
- Documentation updated: Docs reflect the changes
```

**Use answer to**:
- Populate Acceptance Criteria (Section 5)
- Define verification approach (Section 6)
- Set completion criteria

#### Question 10: Performance Targets (Conditional)

Only ask if "Performance met" selected in Question 9 OR Question 2 answered "Performance issue".

```
Question: Do you have measurable performance targets?
Header: Performance
Options:
- Yes, with baseline: I have current baseline and target metrics (Recommended)
- Yes, target only: I have target but need to measure baseline
- No metrics yet: Need to establish baseline and target
- Not applicable: Change not performance-related
```

**Use answer to**:
- Populate Metrics section (6.2) if baseline exists
- Add acceptance criteria for performance
- Flag if baseline measurement needed

### Step 3: Generate CR Content

Using answers from questioning flow and context from Step 1:

1. **Generate Title**: Concise description (≤10 words)
   - Pattern: `[Type] Brief description of change`
   - Example: `Add JWT authentication middleware to API`

2. **Populate Sections** according to Document Structure below:
   - Use artifact-specific language from answers
   - Transform behavioral descriptions to artifact references
   - Fill tables with concrete specifications
   - Add acceptance criteria as checkboxes

3. **Mark Unknown Sections**: If information missing after all questions:
   - Add note: `(Requires clarification - run mdt-clarification.md workflow)`
   - Do NOT use placeholders or TODOs
   - Do NOT fabricate information

4. **Validate Content** against Quality Checklist before submission

### Step 4: Create CR via MCP

```json
{
  "project": "PROJECT_CODE",
  "type": "Architecture|Feature Enhancement|Bug Fix|Technical Debt|Documentation",
  "data": {
    "title": "Generated title from Step 3",
    "phaseEpic": "Optional phase/epic if mentioned in context",
    "assignee": "Optional assignee if mentioned in context",
    "content": "Full markdown content (no YAML frontmatter)"
  }
}
```

**Project Code Discovery**: If not in context, use:
```bash
cat .mdt-config.toml | grep 'code = '
```

### Step 5: Post-Creation Actions

After successful CR creation:

1. **Report CR Key**: Inform user of created CR (e.g., "Created MDT-078")

2. **Suggest Next Steps**:
   - If sections marked "Requires clarification": Suggest running `mdt-clarification.md`
   - If exploratory CR: Suggest implementation spike before approval
   - If ready: Suggest marking as "Approved" for implementation

3. **Offer Immediate Refinement**: Ask if user wants to:
   - Add more detail to any section
   - Run clarification workflow now
   - Make any corrections

---

## Document Structure

## 1. Description

### Problem
Write 2-3 bullets describing specific technical issues:
- Specific technical issue with artifact reference
- Missing capability with artifact reference
- Architectural gap with artifact reference

### Affected Artifacts
List files, components, and endpoints affected:
- `path/to/file.ts` (specific concern)
- `Component/ModuleName` (specific concern)
- `/api/endpoint` (specific concern)

### Scope
Clearly define boundaries:
- **Changes**: What will be modified/created
- **Unchanged**: What stays the same

## 2. Decision

### Chosen Approach
One sentence describing the decision.

### Rationale
Write 3-5 bullets with specific, measurable reasons:
- Technical reason (specific, measurable)
- Technical reason (specific, measurable)
- Trade-off accepted (specific)

## 3. Alternatives Considered

Use table format only:

| Approach | Key Difference | Why Rejected |
|----------|---------------|--------------|
| **Chosen Approach** | One-line description | **ACCEPTED** - Reason for choosing |
| Option A | One-line description | Specific reason |
| Option B | One-line description | Specific reason |

**IMPORTANT**: Mark the chosen approach with **ACCEPTED** in the "Why Rejected" column

## 4. Artifact Specifications

### New Artifacts

| Artifact | Type | Purpose |
|----------|------|---------|
| `src/components/X.tsx` | Component | Feature X UI |
| `/api/new-endpoint` | Endpoint | Data access |
| `services/Y.ts` | Service | Business logic |

### Modified Artifacts

| Artifact | Change Type | Modification |
|----------|-------------|--------------|
| `path/to/file.ts` | Method added | `methodName()` |
| `Component` | Prop changed | Added `propName` |

### Integration Points

| From | To | Interface |
|------|----|-----------| 
| Component X | Service Y | Method Z |
| API endpoint | Database | Query type |

### Key Patterns
List patterns as bullets:
- Pattern name: Where applied (artifact reference)
- Pattern name: Where applied (artifact reference)

## 5. Acceptance Criteria

### Functional
Write artifact-specific, testable criteria as checkboxes (NOT in code blocks):
- [ ] File X exports method Y
- [ ] Component Z renders when condition A
- [ ] Endpoint /api/path returns status 200 for input B

### Non-Functional
Write measurable criteria as checkboxes (NOT in code blocks):
- [ ] Test coverage > X% (current: Y%)
- [ ] Operation completes in < Nms (current: Mms)
- [ ] Error type E thrown when condition F

### Testing
Write specific test cases as bullets (NOT in code blocks):
- Unit: Test file X, function Y, input Z → output W
- Integration: Component A + Service B → State C
- Manual: Action sequence → verify result

## 6. Verification

### By CR Type
Choose the appropriate verification approach:
- **Bug Fix**: Issue X no longer occurs in test case Y
- **Feature**: Artifact X exists and test Y passes
- **Refactoring**: Tests pass, metric M improved (before: A, after: B)
- **Performance**: Operation X < target (baseline: Y, target: Z)
- **Documentation**: Files [list] contain sections [list]

### Metrics
ONLY include metrics if ALL three conditions met:
1. Baseline measurement exists
2. Can be verified through testing/measurement
3. CR explicitly targets this metric

If no metrics applicable, list verifiable artifacts that exist after implementation.

## 7. Deployment

### Simple Changes
Use bullets:
- Deployment method
- Configuration changes required

### Complex Changes
Use table format:

| Phase | Artifacts Deployed | Rollback |
|-------|-------------------|----------|
| 1 | File A, B | Revert commits X, Y |
| 2 | File C, D | Disable feature flag |

Code blocks ARE allowed in this section for deployment commands:
```bash
npm run deploy
kubectl apply -f config.yaml
```

---

## Quality Checklist

Before submitting, verify:
- [ ] Every technical statement references a concrete artifact (file/component/endpoint/method)
- [ ] NO paragraphs describing "what it does" - only specifications of what exists
- [ ] Problem section references specific artifacts that have the problem
- [ ] Alternatives table shows concrete differences, not philosophy
- [ ] Section 4 uses tables for specifications
- [ ] Acceptance criteria reference specific artifacts and tests
- [ ] Verification is measurable or references concrete artifacts
- [ ] NO generic adjectives without supporting specifics
- [ ] Section headers use `##` and `###`, NEVER bold text like `**Header**`
- [ ] NO duplicate headers (never repeat the same section header)
- [ ] Lists are NOT wrapped in code blocks (except Section 7 deployment commands)
- [ ] Only ONE H1 (`#`) header - the document title
- [ ] All metrics have baselines OR section describes artifacts only
- [ ] Alternatives table clearly marks chosen approach with **ACCEPTED**

## Common Errors to Avoid

❌ **WRONG**: `**Problem**` (bold as header)
✅ **CORRECT**: `### Problem` (markdown header)

❌ **WRONG**: Duplicate headers like `## 1. Description` appearing twice
✅ **CORRECT**: Each header appears only once

❌ **WRONG**: Behavioral descriptions like "Component that handles authentication"
✅ **CORRECT**: Artifact specifications like "`AuthService.ts` - Authentication logic"

---

This ensures artifact-focused, properly formatted specification documents.