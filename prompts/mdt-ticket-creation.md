# ADR Template for MCP mdt-all (v2 - Specification-First)

Guide for AI agents creating architectural decision records (ADRs) using MCP mdt-all ticket system.

**Core Principle**: This is an ARTIFACT SPECIFICATION, not a narrative document. Every statement must reference concrete code artifacts (files, components, endpoints, classes, functions). No descriptions of "what it does" - only specifications of "what exists".

## Critical Rules

1. **NO YAML frontmatter** - Auto-generated by MCP
2. **NO prose paragraphs** - Use bullets, tables, or lists only
3. **NO descriptions** - Specify artifacts (files, components, endpoints), not behavior descriptions
4. **NO "it does X" statements** - Say "Component Y" not "Component that does Y"
5. **NO placeholders** - Replace ALL with concrete details
6. **NO fabricated metrics** - Only if: (a) baseline exists, (b) verifiable, (c) explicitly required
7. **NO unmeasurable claims** - No adoption rates, productivity, satisfaction, time estimates
8. **NO generic adjectives** - No "user-friendly", "robust", "scalable", "efficient" without specifics
9. **NO implementation code** - No code snippets, API signatures, config files, schemas
10. **ARTIFACT REFERENCES REQUIRED** - Every technical point must name a file/component/endpoint
11. **Tables over paragraphs** - Use tables for comparisons and specifications
12. **Keep concise** - Target 150-300 lines

## MCP Tool Usage

```json
{
  "project": "PROJECT_CODE",
  "type": "Architecture|Feature Enhancement|Bug Fix|Documentation",
  "data": {
    "title": "CR title",
    "phaseEpic": "Optional phase/epic",
    "assignee": "Optional team/person",
    "content": "Full markdown (no YAML)"
  }
}
```

---

## Document Structure

### 1. Problem & Scope

**Problem** (2-3 bullets):
- Specific technical issue
- Missing capability
- Architectural gap

**Affected Artifacts**:
- `path/to/file.ts`
- `Component/ModuleName`
- `/api/endpoint`

**Scope** (bullets):
- What changes
- What doesn't change

### 2. Decision

**Chosen Approach** (1 sentence):
Brief statement of the decision

**Rationale** (3-5 bullets):
- Technical reason (specific, measurable)
- Technical reason (specific, measurable)
- Trade-off accepted

### 3. Alternatives Considered

Use table format:

| Approach | Key Difference | Why Rejected |
|----------|---------------|--------------|
| Option A | One-line description | Specific reason |
| Option B | One-line description | Specific reason |

### 4. Artifact Specifications

**CRITICAL**: This section lists WHAT artifacts exist/change, NOT what they do.

#### New Artifacts

| Artifact | Type | Purpose |
|----------|------|---------|
| `src/components/X.tsx` | Component | Feature X UI |
| `/api/new-endpoint` | Endpoint | Data access |
| `services/Y.ts` | Service | Business logic |

#### Modified Artifacts

| Artifact | Change Type | Modification |
|----------|-------------|--------------|
| `path/to/file.ts` | Method added | `methodName()` |
| `Component` | Prop changed | Added `propName` |

#### Integration Points

| From | To | Interface |
|------|----|-----------| 
| Component X | Service Y | Method Z |
| API endpoint | Database | Query type |

#### Key Patterns

- Pattern name: Where applied
- Pattern name: Where applied

**NO code examples unless absolutely critical to decision**

### 5. Acceptance Criteria

**Functional** (artifact-specific, testable):

- [ ] File X exports method Y
- [ ] Component Z renders when condition A
- [ ] Endpoint /api/path returns status 200 for input B


**Non-Functional** (measurable):

- [ ] Test coverage > X% (current: Y%)
- [ ] Operation completes in < Nms (current: Mms)
- [ ] Error type E thrown when condition F


**Testing** (specific test cases):

- Unit: Test file X, function Y, input Z → output W
- Integration: Component A + Service B → State C
- Manual: Action sequence → verify result


### 6. Verification

**By CR Type**:

- **Bug Fix**: Issue X no longer occurs in test case Y
- **Feature**: Artifact X exists and test Y passes
- **Refactoring**: Tests pass, metric M improved (before: A, after: B)
- **Performance**: Operation X < target (baseline: Y, target: Z)
- **Documentation**: Files [list] contain sections [list]

**ONLY include metrics if all three conditions met**:
1. Baseline measurement exists
2. Can be verified through testing/measurement
3. CR explicitly targets this metric

**If no metrics**: List verifiable artifacts that exist after implementation

### 7. Deployment

**Simple changes**:
- Deployment method
- Configuration changes required

**Complex changes** (table format):

| Phase | Artifacts Deployed | Rollback |
|-------|-------------------|----------|
| 1 | File A, B | Revert commits X, Y |
| 2 | File C, D | Disable feature flag |

---

## Format Examples

### ✅ GOOD - Artifact Specification:

Modified Artifacts:
- `src/hooks/useAuth.ts`: Added `validateToken()` method
- `src/api/routes.ts`: New endpoint `/api/auth/refresh`
- `LoginComponent`: Added `onTokenExpired` prop


### ❌ BAD - Behavioral Description:

The authentication system now handles token expiration gracefully by 
validating tokens and providing a seamless refresh mechanism that 
improves user experience and maintains session security.


### ✅ GOOD - Decision Rationale:

- JWT tokens expire after 15min (security requirement)
- Refresh without re-login required (UX requirement)
- Existing session management incompatible with auto-refresh


### ❌ BAD - Generic Rationale:

This change improves security while maintaining a user-friendly 
experience and aligns with industry best practices for modern 
web applications.


### ✅ GOOD - Verification:
- Bug Fix: Race condition in `handleSubmit()` no longer occurs (test: `auth.test.ts:45`)
- Metric: Response time < 200ms (baseline: 450ms, measured: 180ms)


### ❌ BAD - Verification:
- Improved system performance and reliability
- Better user experience with faster response times
- Enhanced error handling for edge cases

---

## Before Submitting

- [ ] Every technical statement references a concrete artifact (file/component/endpoint/method)
- [ ] NO paragraphs describing "what it does" - only specifications of what exists
- [ ] Problem references specific artifacts that have the problem
- [ ] Alternatives table shows concrete differences, not philosophy
- [ ] Section 4 is a specification list/table, not prose
- [ ] Acceptance criteria reference specific artifacts and tests
- [ ] Verification is measurable or references concrete artifacts
- [ ] NO generic adjectives without supporting specifics
- [ ] NO "user-friendly/robust/scalable" language
- [ ] All metrics have baselines OR section describes artifacts only

---

This ensures artifact-focused, specification-style architectural tickets.