# ADR Template for MCP mdt-all

Guide for AI agents creating architectural decision records (ADRs) using MCP mdt-all ticket system.

## Critical Rules

1. **NO YAML frontmatter** - Auto-generated by MCP
2. **NO redundancy** - Each point made once
3. **NO placeholders** - Replace with concrete details
4. **NO fabricated metrics** - Only real baselines
5. **NO implementation details**: No code snippets, API signatures, config files, implementation steps, or database schemas
6. **This is a DECISION document** - Answer "what and why", not "how to code it"
7. **Testable criteria** - "API returns 200 OK" not "works well"
8. **Specific tests** - "Function X throws ErrorY when Z" not "test error handling"
9. **Skip optional sections** - If simple change, omit deployment strategy
10. **Keep concise** - Target 200-400 lines

## MCP Tool Usage

```json
{
  "project": "PROJECT_CODE",
  "type": "Architecture|Feature Enhancement|Bug Fix|Documentation",
  "data": {
    "title": "CR title",
    "phaseEpic": "Optional phase/epic",
    "assignee": "Optional team/person",
    "content": "Full markdown (no YAML)"
  }
}
```

Find project code in your knowledge, ask user, or check projects list.

---

## Document Structure

### 1. Description
- **Problem**: What + why it matters (2-3 sentences)
- **Current State**: Key components and pain points (brief)
- **Desired State**: Outcome-focused goals (3-5 bullets)
- **Impact Areas**: Affected system parts (bullets)

### 2. Decision Rationale
- **Why necessary**: 2-3 business/technical reasons
- **What it accomplishes**: Measurable outcomes and benefits
- **Project alignment**: How it fits objectives

### 3. Solution Analysis

For each approach:
```
#### Approach A: [Name] (Chosen/Rejected)
**Description**: One sentence
**Pros**: 3-4 benefits
**Cons**: 1-2 trade-offs
```

Then:
- **Decision Factors**: Criteria and constraints (bullets)
- **Justification**: Why chosen approach wins (1 paragraph)

### 4. Implementation Specification

**What to include**:
- Component names and responsibilities
- Integration points between systems
- Technology/pattern choices with justification
- High-level architecture

**What to avoid**: Code examples, API definitions, config files, implementation steps, schemas

**Goal**: Developer knows WHAT to build and WHY, figures out HOW themselves

### 5. Acceptance Criteria

**Functional** (testable):
```
- [ ] Component X does Y when Z
- [ ] User completes workflow A→B→C
```

**Non-Functional** (measurable):
```
- Reliability: Error X handled as Y
- Maintainability: Follows pattern Z
- Security: Input validated against Y
- Performance: Operation < X ms
```

**Testing** (concrete scenarios):
```
- Unit: Function X(input) returns Y, throws Error when Z
- Integration: User→Action→Response→State
- Manual: Specific UI flow to verify
```

### 6. Success Metrics

**Only if baselines exist**:
- Performance: "Response < 200ms" (current: 350ms)
- Resources: "Memory < 100MB" (current: 180MB)  
- Quality: "Coverage > 80%" (current: 65%)

**Otherwise**: Describe qualitative improvements

### 7. Deployment Strategy

**Simple**: 1-2 sentences + config/restart needs

**Complex**: Phase breakdown with what/when

**Always**: Include rollback plan

---

## Diagrams

Use Mermaid for: architecture, component relationships, data flow

Keep: simple, minimal colors, clear labels

---

## Before Submitting

- [ ] Specific problem (no vague statements)
- [ ] Clear decision justification
- [ ] Multiple approaches compared
- [ ] Testable criteria (no "works well")
- [ ] Specific test scenarios
- [ ] Real metrics OR qualitative description
- [ ] NO implementation details
- [ ] Rollback plan
- [ ] All placeholders replaced

